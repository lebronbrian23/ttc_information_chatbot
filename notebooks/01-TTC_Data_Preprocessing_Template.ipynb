{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTC Delay Data Preprocessing - Task Template\n",
    "\n",
    "**Goal:** Clean and preprocess delay data from 2024 and 2025 for Phase 1 modeling\n",
    "\n",
    "**Input Files:**\n",
    "- `ttc-subway-delay-2024.xlsx`\n",
    "- `ttc-subway-delay-data-since-2025.csv`\n",
    "\n",
    "**Output File:**\n",
    "- `cleaned_ttc_delay_data.csv`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports\n",
    "\n",
    "Import required libraries and load both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import pandas, numpy, and any other libraries you need\n",
    "# Hint: You'll need pandas for data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load 2024 Excel file\n",
    "# Hint: Use pd.read_excel() with sheet_name='Subway'\n",
    "# Store in variable: df_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load 2025 CSV file\n",
    "# Hint: Use pd.read_csv()\n",
    "# Store in variable: df_2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Combine both dataframes\n",
    "# Hint: Use pd.concat() with ignore_index=True\n",
    "# Store in variable: df (this will be your main dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Inspect the combined dataframe\n",
    "# Hint: Check shape, columns, first few rows, data types, info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1: Standardize Line Names\n",
    "\n",
    "**Objective:** Map all inconsistent line names to canonical forms (Line 1, Line 2, Line 4)\n",
    "\n",
    "**Current Issues:**\n",
    "- YU, YU/BD, YU / BD, YU/ BD, LINE 1 → Should all be \"Line 1\"\n",
    "- BD, BLOOR DANFORTH, BD/YU, BD / YU → Should all be \"Line 2\"\n",
    "- SHP, SHEP → Should be \"Line 4\"\n",
    "- Invalid: 109 RANEE, 20 CLIFFSIDE, TRACK LEVEL ACTIVITY → Should be removed\n",
    "\n",
    "**Hints:**\n",
    "1. First, check `df['Line'].unique()` to see all variations\n",
    "2. Create a mapping dictionary with old name → new name\n",
    "3. Use `.map()` or `.replace()` to apply the mapping\n",
    "4. For multi-line entries (YU/BD), decide: keep as \"Line 1/2\" or drop\n",
    "5. Verify after mapping: check unique values again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Examine current Line values\n",
    "# Print unique values and counts\n",
    "# Hint: df['Line'].unique() and df['Line'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create mapping dictionary\n",
    "# Map all variations to canonical names\n",
    "# Example structure:\n",
    "# line_mapping = {\n",
    "#     'YU': 'Line 1',\n",
    "#     'YU/BD': 'Line 1/2',\n",
    "#     ... (add all variations)\n",
    "# }\n",
    "# Hint: Reference the task guide for all 22 variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply mapping to Line column\n",
    "# Hint: Use df['Line'].map(line_mapping) or df['Line'].replace(line_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Verify mapping worked\n",
    "# Check unique values after mapping\n",
    "# Should see only: Line 1, Line 2, Line 4, Line 1/2, etc. (canonical forms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2: Remove Invalid Records\n",
    "\n",
    "**Objective:** Remove rows with missing or erroneous Line values\n",
    "\n",
    "**Records to Remove:**\n",
    "- ~44-67 rows with null/NaN Line values\n",
    "- Erroneous entries like \"109 RANEE\", \"20 CLIFFSIDE\", \"TRACK LEVEL ACTIVITY\"\n",
    "\n",
    "**Hints:**\n",
    "1. Check `df['Line'].isnull().sum()` to count nulls\n",
    "2. Use `df.dropna(subset=['Line'])` to remove null rows\n",
    "3. Use `df[~df['Line'].isin(['list', 'of', 'invalid', 'values'])]` to filter invalid entries\n",
    "4. Log record counts before and after to confirm removal\n",
    "5. Expected result: ~52,000-52,064 records remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check for null Line values\n",
    "# Print count of nulls and percentage\n",
    "# Hint: df['Line'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove rows with null Line\n",
    "# Store record count before and after\n",
    "# Hint: Use .dropna() or boolean indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove erroneous entries\n",
    "# Create list of invalid values to remove\n",
    "# Hint: Use df[~df['Line'].isin(['invalid', 'entries'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Log results\n",
    "# Print: Original record count, Records removed, Final count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 3: Parse Time Column\n",
    "\n",
    "**Objective:** Extract hour from Time column (HH:MM format → integer 0-23)\n",
    "\n",
    "**Current Format:** Text like \"02:00\", \"08:46\", \"17:05\"\n",
    "\n",
    "**Hints:**\n",
    "1. Create function to parse time strings\n",
    "2. Split on \":\" character and take first part\n",
    "3. Convert to integer\n",
    "4. Use `.apply()` to apply function to entire column\n",
    "5. Verify: all values should be 0-23, no nulls\n",
    "6. Drop original Time column after extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Examine Time column\n",
    "# Check sample values, data type, unique counts\n",
    "# Hint: df['Time'].head(10), df['Time'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create function to extract hour\n",
    "# Function should:\n",
    "# - Take time string as input\n",
    "# - Split on ':'\n",
    "# - Return first part as integer\n",
    "# - Handle errors gracefully\n",
    "# Hint: def extract_hour(time_str):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create 'hour' column\n",
    "# Apply function to Time column\n",
    "# Hint: df['hour'] = df['Time'].apply(extract_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Validate hour values\n",
    "# Check: min, max, data type, any nulls\n",
    "# Should be: min=0, max=23, type=int, nulls=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Drop Time column (no longer needed)\n",
    "# Hint: df.drop(columns=['Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 4: Parse Date Column\n",
    "\n",
    "**Objective:** Ensure Date is datetime format and extract temporal features (year, month, week)\n",
    "\n",
    "**Current State:**\n",
    "- 2024 file: already datetime\n",
    "- 2025 file: text format \"2025-01-01\"\n",
    "\n",
    "**Hints:**\n",
    "1. Check current data type: `df['Date'].dtype`\n",
    "2. Convert to datetime: `pd.to_datetime(df['Date'])`\n",
    "3. Extract year: `df['Date'].dt.year`\n",
    "4. Extract month: `df['Date'].dt.month`\n",
    "5. Extract week: `df['Date'].dt.isocalendar().week`\n",
    "6. Verify: year should be 2024 or 2025, month 1-12, week 1-53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check current Date format\n",
    "# Check data type and sample values\n",
    "# Hint: df['Date'].dtype, df['Date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert Date to datetime\n",
    "# Hint: df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract year\n",
    "# Create column 'year' with values 2024 or 2025\n",
    "# Hint: df['year'] = df['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract month\n",
    "# Create column 'month' with values 1-12\n",
    "# Hint: df['month'] = df['Date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract week\n",
    "# Create column 'week' with values 1-53\n",
    "# Hint: df['week'] = df['Date'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Validate temporal columns\n",
    "# Check ranges: year (2024-2025), month (1-12), week (1-53)\n",
    "# Check for any nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 5: Define Target Variable\n",
    "\n",
    "**Objective:** Create binary 'is_delayed' column (0=on-time, 1=delayed)\n",
    "\n",
    "**Decision:** What threshold defines \"delayed\"?\n",
    "- **Recommended: 5 minutes**\n",
    "- Alternative: 10 minutes\n",
    "\n",
    "**Hints:**\n",
    "1. Analyze Min Delay distribution first (percentiles, mean, median, max)\n",
    "2. Create rule: if Min Delay >= threshold, then 1, else 0\n",
    "3. Check class balance (should be roughly 70% on-time, 30% delayed)\n",
    "4. Verify: column should have only 0 and 1, no nulls\n",
    "5. Log class distribution percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze Min Delay distribution\n",
    "# Calculate: min, max, mean, median, percentiles (25, 50, 75)\n",
    "# Hint: df['Min Delay'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Decide on delay threshold\n",
    "# Set variable: threshold = 5 (or your chosen value)\n",
    "# Comment why you chose this threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create is_delayed column\n",
    "# If Min Delay >= threshold, then 1, else 0\n",
    "# Hint: df['is_delayed'] = (df['Min Delay'] >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check class distribution\n",
    "# Count of 0s and 1s, and percentages\n",
    "# Hint: df['is_delayed'].value_counts() and normalized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Validate target variable\n",
    "# Check: only 0 and 1 values, no nulls, data type is int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 6: Create Day-of-Week Numeric\n",
    "\n",
    "**Objective:** Convert day names (Monday, Tuesday, etc.) to numeric (0-6)\n",
    "\n",
    "**Mapping:**\n",
    "- Monday → 0\n",
    "- Tuesday → 1\n",
    "- ... \n",
    "- Sunday → 6\n",
    "\n",
    "**Hints:**\n",
    "1. Create mapping dictionary with day names as keys\n",
    "2. Use `.map()` to apply mapping\n",
    "3. Verify: values should be 0-6 only, no nulls\n",
    "4. Spot-check: verify a few rows match expected days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check current Day column\n",
    "# See unique values\n",
    "# Hint: df['Day'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create day mapping dictionary\n",
    "# Map day names to 0-6\n",
    "# Example: {'Monday': 0, 'Tuesday': 1, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create day_of_week column\n",
    "# Apply mapping to Day column\n",
    "# Hint: df['day_of_week'] = df['Day'].map(day_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Validate day_of_week\n",
    "# Check: values 0-6 only, no nulls, data type is int\n",
    "# Spot-check a few rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 7: Create Weekday Indicator\n",
    "\n",
    "**Objective:** Create binary column 'is_weekend' (0=Mon-Fri, 1=Sat-Sun)\n",
    "\n",
    "**Logic:**\n",
    "- If day_of_week >= 5 (Saturday or Sunday), then 1\n",
    "- Else 0\n",
    "\n",
    "**Hints:**\n",
    "1. Use comparison operator: `df['day_of_week'] >= 5`\n",
    "2. Convert boolean to int with `.astype(int)`\n",
    "3. Verify: only 0 and 1 values\n",
    "4. Spot-check: Saturday and Sunday rows should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create is_weekend column\n",
    "# 1 if day_of_week >= 5, else 0\n",
    "# Hint: df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Validate is_weekend\n",
    "# Check: only 0 and 1 values, no nulls\n",
    "# Spot-check: verify Saturday/Sunday are marked as 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 8: Calculate Historical Frequencies\n",
    "\n",
    "**Objective:** Create features showing historical delay patterns\n",
    "\n",
    "**Three features to create:**\n",
    "1. **route_delay_frequency** - % of delays by Line\n",
    "2. **route_hour_delay_frequency** - % of delays by Line + Hour\n",
    "3. **route_day_hour_delay_frequency** - % of delays by Line + Day + Hour\n",
    "\n",
    "**Hints:**\n",
    "1. Group by Line, calculate mean of is_delayed (gives proportion)\n",
    "2. Create mapping: Line → frequency value\n",
    "3. Map back to all rows with the same Line\n",
    "4. Repeat for Line+Hour and Line+Day+Hour combinations\n",
    "5. All values should be between 0 and 1 (proportions)\n",
    "6. Verify: no nulls in any frequency columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate route-level delay frequency\n",
    "# Group by Line, calculate mean of is_delayed\n",
    "# Create mapping and apply to all rows\n",
    "# Store in column: route_delay_frequency\n",
    "# Hint: group_by -> mean -> map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate route-hour delay frequency\n",
    "# Group by Line + Hour combination\n",
    "# Calculate mean of is_delayed\n",
    "# Map back to all rows\n",
    "# Store in column: route_hour_delay_frequency\n",
    "# Hint: Create composite key first: Line + '_' + hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate route-day-hour delay frequency\n",
    "# Group by Line + Day + Hour combination\n",
    "# Calculate mean of is_delayed\n",
    "# Map back to all rows\n",
    "# Store in column: route_day_hour_delay_frequency\n",
    "# Hint: Create composite key: Line + '_' + day_of_week + '_' + hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Validate frequency columns\n",
    "# Check: all values between 0 and 1\n",
    "# Check: no nulls\n",
    "# Sample a few rows to verify values make sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 9: Handle Missing Bound Column\n",
    "\n",
    "**Objective:** Decide what to do with Bound column (has ~36% missing values)\n",
    "\n",
    "**Decision Point:**\n",
    "- **Option A (Recommended): Drop the column** - Simpler, not needed for Phase 1\n",
    "- Option B: Keep and note the missing values\n",
    "\n",
    "**Hints:**\n",
    "1. Check current Bound values: `df['Bound'].unique()` and null count\n",
    "2. If choosing Option A: use `df.drop(columns=['Bound'])`\n",
    "3. If choosing Option B: create `has_bound` indicator (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Examine Bound column\n",
    "# Check unique values, null count, percentage\n",
    "# Hint: df['Bound'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Drop Bound column\n",
    "# Since not needed for Phase 1\n",
    "# Hint: df = df.drop(columns=['Bound'])\n",
    "# OR: Keep it if you prefer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 10: Final Validation\n",
    "\n",
    "**Objective:** Verify all preprocessing is complete and correct\n",
    "\n",
    "**Validation Checklist:**\n",
    "1. No null values in critical columns (Line, hour, day_of_week, is_delayed, is_weekend)\n",
    "2. Data types correct (int, float, datetime, object)\n",
    "3. Value ranges correct (hour 0-23, day_of_week 0-6, frequencies 0-1)\n",
    "4. Record counts reasonable (~52,000-52,064)\n",
    "5. No unexpected data loss\n",
    "\n",
    "**Hints:**\n",
    "1. Use `df.info()` to check data types and nulls\n",
    "2. Use `df.describe()` to check numeric ranges\n",
    "3. Create summary table showing column info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check for null values\n",
    "# List all columns with null counts\n",
    "# Hint: df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check data types\n",
    "# Verify each column has expected type\n",
    "# Expected:\n",
    "#   - Line: object\n",
    "#   - hour, day_of_week, is_weekend, is_delayed: int\n",
    "#   - Frequencies: float\n",
    "#   - Date: datetime\n",
    "# Hint: df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check value ranges\n",
    "# hour: 0-23\n",
    "# day_of_week: 0-6\n",
    "# is_weekend: 0-1\n",
    "# is_delayed: 0-1\n",
    "# month: 1-12\n",
    "# Frequencies: 0-1\n",
    "# Hint: df.describe() and custom checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check record counts by line\n",
    "# Breakdown of records for each line\n",
    "# Should see: Line 1, Line 2, Line 4, etc.\n",
    "# Hint: df['Line'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate validation summary\n",
    "# Create table showing:\n",
    "#   - Column name\n",
    "#   - Data type\n",
    "#   - Null count\n",
    "#   - Min/Max (for numeric)\n",
    "# Hint: Create DataFrame with this info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Final checks\n",
    "# - Total record count\n",
    "# - Date range (should be 2024-2025)\n",
    "# - No unexpected patterns\n",
    "# Print summary statement: \"Validation passed\" or list issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 11: Export Clean Data\n",
    "\n",
    "**Objective:** Save preprocessed data to CSV for modeling\n",
    "\n",
    "**Output File:** `cleaned_ttc_delay_data.csv`\n",
    "\n",
    "**Columns to Include:**\n",
    "- Date, Line, hour, day_of_week, is_weekend\n",
    "- month, week, year\n",
    "- Min Delay (original)\n",
    "- is_delayed (TARGET VARIABLE)\n",
    "- route_delay_frequency, route_hour_delay_frequency, route_day_hour_delay_frequency\n",
    "- Code (delay reason, for exploration)\n",
    "- Station (location, for exploration)\n",
    "\n",
    "**Hints:**\n",
    "1. Select specific columns to keep\n",
    "2. Use `to_csv()` with appropriate parameters\n",
    "3. Read file back in to verify export was successful\n",
    "4. Spot-check 5-10 random rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select columns to keep\n",
    "# Create list of column names to export\n",
    "# Include all required columns from task guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create final dataframe with selected columns\n",
    "# Hint: df_export = df[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Export to CSV\n",
    "# File: cleaned_ttc_delay_data.csv\n",
    "# Parameters:\n",
    "#   - index=False\n",
    "#   - encoding='utf-8'\n",
    "# Hint: df_export.to_csv('cleaned_ttc_delay_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Verify export\n",
    "# Read file back in\n",
    "# Check shape, columns, data types\n",
    "# Hint: df_check = pd.read_csv('cleaned_ttc_delay_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Spot-check exported data\n",
    "# Display 5-10 random rows\n",
    "# Verify data looks correct\n",
    "# Hint: df_check.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Final summary\n",
    "# Print completion message\n",
    "# Example: \"✓ Preprocessing complete! Exported 52,064 records to cleaned_ttc_delay_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "- Follow tasks in order (1-11)\n",
    "- After each task, validate before moving to next\n",
    "- When code is ready, share with me for review\n",
    "- Ask questions if hints are unclear\n",
    "- Final output: `cleaned_ttc_delay_data.csv` ready for Phase 1 modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
